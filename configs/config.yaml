# CodeMentor Configuration File

# Ollama LLM Configuration (for chat/generation)
ollama:
  host: "http://localhost:11434"
  chat_model: "qwen2.5:0.5b"              # Chat model
  embedding_model: "nomic-embed-text"     # Fallback embedding model
  timeout: 300                             # Request timeout in seconds

# Embedding Service Configuration
embedding:
  provider: "codebert"                    # codebert or ollama
  host: "http://localhost:8001"          # CodeBERT service URL (if using codebert)

# Vector Database Configuration
vector:
  type: "qdrant"                          # memory, qdrant
  host: "localhost"
  port: 6333                              # Qdrant default port
  collection: "codementor"
  dimension: 768                          # nomic-embed-text dimension is 768

# Code Indexer Configuration
indexer:
  chunk_size: 1000                        # Target chunk size in characters
  chunk_overlap: 200                      # Overlap between chunks
  extensions:                              # File extensions to index
    - ".go"
    - ".py"
    - ".js"
    - ".ts"
    - ".java"
    - ".rs"
    - ".cpp"
    - ".c"
    - ".h"
    - ".md"
  ignore_dirs:                             # Directories to ignore
    - ".git"
    - "node_modules"
    - "vendor"
    - "__pycache__"
    - ".idea"
    - ".vscode"
    - "target"
    - "build"
    - "dist"

# HTTP Server Configuration
server:
  host: "0.0.0.0"
  port: 8080
